{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part1_BPE_Implementation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Importing packages**"
      ],
      "metadata": {
        "id": "zFcECk5Tv8up"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c_EoBnoAulrL"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, Tuple\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find all unique letters in the corpus"
      ],
      "metadata": {
        "id": "B_H0Sa1xwVj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Find_Vocabulary(Dictionary):\n",
        "    Vocabulary = []\n",
        "    for word in Dictionary:\n",
        "        for string in word:\n",
        "            Vocabulary.append(string)\n",
        "    Vocabulary = list(dict.fromkeys(Vocabulary))\n",
        "    Vocabulary.remove(' ')\n",
        "    return Vocabulary"
      ],
      "metadata": {
        "id": "0t49vFwhwORN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find all most frequent pairs in the corpus"
      ],
      "metadata": {
        "id": "Uo6jrULbwcb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Find_Most_Frequent_Pair(My_Dictionary: Dict[str, int]) -> Dict[Tuple[str, str], int]:\n",
        "    Pair = {}\n",
        "    for Vocab, Frequency in My_Dictionary.items():\n",
        "        Letter = Vocab.split()\n",
        "        for i in range(len(Letter) - 1):\n",
        "            pair = (Letter[i], Letter[i + 1])\n",
        "            New_Frequency = Pair.get(pair, 0)\n",
        "            Pair[pair] = New_Frequency + Frequency\n",
        "    return Pair"
      ],
      "metadata": {
        "id": "GNuevM6kwYT5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge most frequent Consecutive letters into one word"
      ],
      "metadata": {
        "id": "Adl0Skbnwihm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Combine_Vocabulary(Most_Frequent_Pair: Tuple[str, str], Input_Vocabulary: Dict[str, int]) -> Dict[str, int]:\n",
        "    Merged_Vocabulary = {}\n",
        "    pattern = re.escape(' '.join(Most_Frequent_Pair))\n",
        "    Substitution = ''.join(Most_Frequent_Pair)\n",
        "    for Input_Word in Input_Vocabulary:\n",
        "        Output_Word = re.sub(pattern, Substitution, Input_Word)\n",
        "        Merged_Vocabulary[Output_Word] = Input_Vocabulary[Input_Word]\n",
        "    return Merged_Vocabulary"
      ],
      "metadata": {
        "id": "VmHdkdgSwdeE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main {"
      ],
      "metadata": {
        "id": "gQCvjXKgwmMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Dictionary = {\n",
        "    'l o w _': 5,\n",
        "    'l o w e r _': 2,\n",
        "    'w i d e s t _': 3,\n",
        "    'n e w e s t _': 5\n",
        "}\n",
        "\n",
        "Vocabulary = Find_Vocabulary(Dictionary)\n",
        "Number_Of_Iteration = 0\n",
        "Number_Of_Final_Vocab = 26\n",
        "# Limitation for the number of final vocabulary\n",
        "while len(Vocabulary)<Number_Of_Final_Vocab:\n",
        "\n",
        "    print('Step:', Number_Of_Iteration)\n",
        "    pair_stats = Find_Most_Frequent_Pair(Dictionary)\n",
        "    if not pair_stats:\n",
        "        break\n",
        "    Most_Frequent_Pair = max(pair_stats, key=pair_stats.get)\n",
        "    print('\\nVocabulary: ', Vocabulary)\n",
        "    Vocabulary.append(Most_Frequent_Pair[0]+Most_Frequent_Pair[1])\n",
        "    print('Dictionary: ', Dictionary)\n",
        "    print('Combined pairs:', Most_Frequent_Pair,'\\n--------------')\n",
        "    Dictionary = Combine_Vocabulary(Most_Frequent_Pair, Dictionary)\n",
        "    Number_Of_Iteration = Number_Of_Iteration + 1\n",
        "\n",
        "print('\\nFinal Dictionary: ', Dictionary)\n",
        "print('Final Vocabulary: ', Vocabulary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkuHlc_Xwj7I",
        "outputId": "5afb398d-0a92-410e-8e9c-4764b1554615"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0\n",
            "\n",
            "Vocabulary:  ['l', 'o', 'w', '_', 'e', 'r', 'i', 'd', 's', 't', 'n']\n",
            "Dictionary:  {'l o w _': 5, 'l o w e r _': 2, 'w i d e s t _': 3, 'n e w e s t _': 5}\n",
            "Combined pairs: ('e', 's') \n",
            "--------------\n",
            "Step: 1\n",
            "\n",
            "Vocabulary:  ['l', 'o', 'w', '_', 'e', 'r', 'i', 'd', 's', 't', 'n', 'es']\n",
            "Dictionary:  {'l o w _': 5, 'l o w e r _': 2, 'w i d es t _': 3, 'n e w es t _': 5}\n",
            "Combined pairs: ('es', 't') \n",
            "--------------\n",
            "Step: 2\n",
            "\n",
            "Vocabulary:  ['l', 'o', 'w', '_', 'e', 'r', 'i', 'd', 's', 't', 'n', 'es', 'est']\n",
            "Dictionary:  {'l o w _': 5, 'l o w e r _': 2, 'w i d est _': 3, 'n e w est _': 5}\n",
            "Combined pairs: ('est', '_') \n",
            "--------------\n",
            "Step: 3\n",
            "\n",
            "Vocabulary:  ['l', 'o', 'w', '_', 'e', 'r', 'i', 'd', 's', 't', 'n', 'es', 'est', 'est_']\n",
            "Dictionary:  {'l o w _': 5, 'l o w e r _': 2, 'w i d est_': 3, 'n e w est_': 5}\n",
            "Combined pairs: ('l', 'o') \n",
            "--------------\n",
            "Step: 4\n",
            "\n",
            "Vocabulary:  ['l', 'o', 'w', '_', 'e', 'r', 'i', 'd', 's', 't', 'n', 'es', 'est', 'est_', 'lo']\n",
            "Dictionary:  {'lo w _': 5, 'lo w e r _': 2, 'w i d est_': 3, 'n e w est_': 5}\n",
            "Combined pairs: ('lo', 'w') \n",
            "--------------\n",
            "Step: 5\n",
            "\n",
            "Vocabulary:  ['l', 'o', 'w', '_', 'e', 'r', 'i', 'd', 's', 't', 'n', 'es', 'est', 'est_', 'lo', 'low']\n",
            "Dictionary:  {'low _': 5, 'low e r _': 2, 'w i d est_': 3, 'n e w est_': 5}\n",
            "Combined pairs: ('low', '_') \n",
            "--------------\n",
            "Step: 6\n",
            "\n",
            "Vocabulary:  ['l', 'o', 'w', '_', 'e', 'r', 'i', 'd', 's', 't', 'n', 'es', 'est', 'est_', 'lo', 'low', 'low_']\n",
            "Dictionary:  {'low_': 5, 'low e r _': 2, 'w i d est_': 3, 'n e w est_': 5}\n",
            "Combined pairs: ('n', 'e') \n",
            "--------------\n",
            "Step: 7\n",
            "\n",
            "Vocabulary:  ['l', 'o', 'w', '_', 'e', 'r', 'i', 'd', 's', 't', 'n', 'es', 'est', 'est_', 'lo', 'low', 'low_', 'ne']\n",
            "Dictionary:  {'low_': 5, 'low e r _': 2, 'w i d est_': 3, 'ne w est_': 5}\n",
            "Combined pairs: ('ne', 'w') \n",
            "--------------\n",
            "Step: 8\n",
            "\n",
            "Vocabulary:  ['l', 'o', 'w', '_', 'e', 'r', 'i', 'd', 's', 't', 'n', 'es', 'est', 'est_', 'lo', 'low', 'low_', 'ne', 'new']\n",
            "Dictionary:  {'low_': 5, 'low e r _': 2, 'w i d est_': 3, 'new est_': 5}\n",
            "Combined pairs: ('new', 'est_') \n",
            "--------------\n",
            "Step: 9\n",
            "\n",
            "Vocabulary:  ['l', 'o', 'w', '_', 'e', 'r', 'i', 'd', 's', 't', 'n', 'es', 'est', 'est_', 'lo', 'low', 'low_', 'ne', 'new', 'newest_']\n",
            "Dictionary:  {'low_': 5, 'low e r _': 2, 'w i d est_': 3, 'newest_': 5}\n",
            "Combined pairs: ('w', 'i') \n",
            "--------------\n",
            "Step: 10\n",
            "\n",
            "Vocabulary:  ['l', 'o', 'w', '_', 'e', 'r', 'i', 'd', 's', 't', 'n', 'es', 'est', 'est_', 'lo', 'low', 'low_', 'ne', 'new', 'newest_', 'wi']\n",
            "Dictionary:  {'low_': 5, 'low e r _': 2, 'wi d est_': 3, 'newest_': 5}\n",
            "Combined pairs: ('wi', 'd') \n",
            "--------------\n",
            "Step: 11\n",
            "\n",
            "Vocabulary:  ['l', 'o', 'w', '_', 'e', 'r', 'i', 'd', 's', 't', 'n', 'es', 'est', 'est_', 'lo', 'low', 'low_', 'ne', 'new', 'newest_', 'wi', 'wid']\n",
            "Dictionary:  {'low_': 5, 'low e r _': 2, 'wid est_': 3, 'newest_': 5}\n",
            "Combined pairs: ('wid', 'est_') \n",
            "--------------\n",
            "Step: 12\n",
            "\n",
            "Vocabulary:  ['l', 'o', 'w', '_', 'e', 'r', 'i', 'd', 's', 't', 'n', 'es', 'est', 'est_', 'lo', 'low', 'low_', 'ne', 'new', 'newest_', 'wi', 'wid', 'widest_']\n",
            "Dictionary:  {'low_': 5, 'low e r _': 2, 'widest_': 3, 'newest_': 5}\n",
            "Combined pairs: ('low', 'e') \n",
            "--------------\n",
            "Step: 13\n",
            "\n",
            "Vocabulary:  ['l', 'o', 'w', '_', 'e', 'r', 'i', 'd', 's', 't', 'n', 'es', 'est', 'est_', 'lo', 'low', 'low_', 'ne', 'new', 'newest_', 'wi', 'wid', 'widest_', 'lowe']\n",
            "Dictionary:  {'low_': 5, 'lowe r _': 2, 'widest_': 3, 'newest_': 5}\n",
            "Combined pairs: ('lowe', 'r') \n",
            "--------------\n",
            "Step: 14\n",
            "\n",
            "Vocabulary:  ['l', 'o', 'w', '_', 'e', 'r', 'i', 'd', 's', 't', 'n', 'es', 'est', 'est_', 'lo', 'low', 'low_', 'ne', 'new', 'newest_', 'wi', 'wid', 'widest_', 'lowe', 'lower']\n",
            "Dictionary:  {'low_': 5, 'lower _': 2, 'widest_': 3, 'newest_': 5}\n",
            "Combined pairs: ('lower', '_') \n",
            "--------------\n",
            "\n",
            "Final Dictionary:  {'low_': 5, 'lower_': 2, 'widest_': 3, 'newest_': 5}\n",
            "Final Vocabulary:  ['l', 'o', 'w', '_', 'e', 'r', 'i', 'd', 's', 't', 'n', 'es', 'est', 'est_', 'lo', 'low', 'low_', 'ne', 'new', 'newest_', 'wi', 'wid', 'widest_', 'lowe', 'lower', 'lower_']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize Out of Vocabulary"
      ],
      "metadata": {
        "id": "o_M5Hxh0dusV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = 'lowest'\n",
        "input = input + '_'\n",
        "Output_Pairs = []\n",
        "Intended_Pairs = []\n",
        "for Vocab in Vocabulary:\n",
        "  if Vocab in input:\n",
        "    Output_Pairs.append(Vocab)\n",
        "for char1 in Output_Pairs:\n",
        "  for char2 in Output_Pairs:\n",
        "    if char1+char2 == input:\n",
        "      Intended_Pairs = [char1,char2]\n",
        "    if char2+char1 == input:\n",
        "      Intended_Pairs = [char2,char1]\n",
        "print('Input Out of Vocabulary is : ',input)\n",
        "print('Intended Pairs are : ',Intended_Pairs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-koIQoynT2vc",
        "outputId": "6f67b64d-55e9-49d9-8cbf-575de70530dc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Out of Vocabulary is :  lowest_\n",
            "Intended Pairs are :  ['low', 'est_']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1V1qoRvid8u5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}